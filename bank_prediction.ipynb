{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 91719,
          "databundleVersionId": 12937777,
          "sourceType": "competition"
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "bank prediction",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faryalrifaz/First-Notebook-on-Kaggle/blob/main/bank_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "h0Zhpj9KKScK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "playground_series_s5e8_path = kagglehub.competition_download('playground-series-s5e8')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "N6sbs8uRKScL"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaggle Playground 2025-08: Bank Term Deposit â€” CV-safe CatBoost baseline\n",
        "# Author: Faryal | Seeded, fold-logged, submission-ready\n",
        "# Notes:\n",
        "# - Auto-detects train/test under /kaggle/input where possible.\n",
        "# - Uses StratifiedKFold, CatBoost (categoricals), early stopping.\n",
        "# - Falls back to LightGBM with simple categorical handling if CatBoost missing.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import gc\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "SEED = 42\n",
        "FOLDS = 5\n",
        "RANDOM_STATE = SEED\n",
        "\n",
        "def seed_everything(seed: int = SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "seed_everything(SEED)\n",
        "\n",
        "def find_competition_root() -> Optional[str]:\n",
        "    # Try to locate a directory under /kaggle/input containing train.csv, test.csv, sample_submission.csv\n",
        "    input_root = \"/kaggle/input\"\n",
        "    if not os.path.isdir(input_root):\n",
        "        return None\n",
        "    candidates = []\n",
        "    for path in glob.glob(os.path.join(input_root, \"*\")):\n",
        "        if os.path.isdir(path):\n",
        "            train_p = os.path.join(path, \"train.csv\")\n",
        "            test_p  = os.path.join(path, \"test.csv\")\n",
        "            sample_p= os.path.join(path, \"sample_submission.csv\")\n",
        "            if os.path.isfile(train_p) and os.path.isfile(test_p) and os.path.isfile(sample_p):\n",
        "                candidates.append(path)\n",
        "    if len(candidates) == 1:\n",
        "        return candidates[0]\n",
        "    # Prefer paths that look like playground series\n",
        "    for p in candidates:\n",
        "        name = os.path.basename(p).lower()\n",
        "        if \"playground\" in name or \"ps\" in name:\n",
        "            return p\n",
        "    return candidates[0] if candidates else None\n",
        "\n",
        "def load_data(root: Optional[str]=None) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    if root is None:\n",
        "        root = find_competition_root()\n",
        "    if root is None:\n",
        "        raise FileNotFoundError(\"Could not auto-detect competition data. Set DATA_ROOT manually to the folder containing train.csv/test.csv.\")\n",
        "    print(f\"[Info] Using data root: {root}\")\n",
        "    train = pd.read_csv(os.path.join(root, \"train.csv\"))\n",
        "    test  = pd.read_csv(os.path.join(root, \"test.csv\"))\n",
        "    sample= pd.read_csv(os.path.join(root, \"sample_submission.csv\"))\n",
        "    return train, test, sample\n",
        "\n",
        "def infer_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
        "    cols = df.columns.tolist()\n",
        "    id_col = \"id\" if \"id\" in cols else None\n",
        "    target_col = \"y\" if \"y\" in cols else (\"target\" if \"target\" in cols else None)\n",
        "    if target_col is None:\n",
        "        raise KeyError(\"Target column not found. Expected 'y' or 'target'.\")\n",
        "    return {\"id\": id_col, \"target\": target_col}\n",
        "\n",
        "def detect_feature_types(df: pd.DataFrame, id_col: Optional[str], target_col: Optional[str]) -> Tuple[List[str], List[str]]:\n",
        "    feature_cols = [c for c in df.columns if c not in [id_col, target_col] and c is not None]\n",
        "    # Categorical: object or low-cardinality integer-like\n",
        "    cat_cols = []\n",
        "    num_cols = []\n",
        "    for c in feature_cols:\n",
        "        if df[c].dtype == \"object\":\n",
        "            cat_cols.append(c)\n",
        "        else:\n",
        "            # Heuristic: small unique counts => treat as categorical\n",
        "            nunique = df[c].nunique(dropna=True)\n",
        "            if str(df[c].dtype).startswith((\"int\", \"uint\")) and nunique <= 32:\n",
        "                cat_cols.append(c)\n",
        "            else:\n",
        "                num_cols.append(c)\n",
        "    print(f\"[Info] Detected {len(feature_cols)} features -> {len(num_cols)} numeric, {len(cat_cols)} categorical\")\n",
        "    return num_cols, cat_cols\n",
        "\n",
        "def safe_numeric_transform(df: pd.DataFrame, num_cols: List[str]) -> pd.DataFrame:\n",
        "    # Minimal numeric cleaning: clip extreme outliers at 0.5th and 99.5th percentiles per column\n",
        "    df = df.copy()\n",
        "    for c in num_cols:\n",
        "        if df[c].dtype.kind in \"biufc\":\n",
        "            lo, hi = df[c].quantile([0.005, 0.995])\n",
        "            df[c] = df[c].clip(lo, hi)\n",
        "    return df\n",
        "\n",
        "def prepare_catboost_data(train: pd.DataFrame, test: pd.DataFrame, id_col: Optional[str], target_col: str) -> Tuple[pd.DataFrame, pd.DataFrame, List[int]]:\n",
        "    num_cols, cat_cols = detect_feature_types(train, id_col, target_col)\n",
        "    # Align dtypes: ensure categorical columns are strings consistently\n",
        "    for c in cat_cols:\n",
        "        train[c] = train[c].astype(\"category\")\n",
        "        test[c]  = test[c].astype(\"category\")\n",
        "    for c in num_cols:\n",
        "        # Ensure numeric\n",
        "        train[c] = pd.to_numeric(train[c], errors=\"coerce\")\n",
        "        test[c]  = pd.to_numeric(test[c], errors=\"coerce\")\n",
        "    # Clip numeric outliers\n",
        "    train[num_cols] = safe_numeric_transform(train, num_cols)[num_cols]\n",
        "    test[num_cols]  = safe_numeric_transform(test, num_cols)[num_cols]\n",
        "    features = num_cols + cat_cols\n",
        "    cat_idx = [features.index(c) for c in cat_cols]\n",
        "    return train[features + [target_col]], test[features], cat_idx\n",
        "\n",
        "def train_catboost_cv(train_df: pd.DataFrame, test_df: pd.DataFrame, target_col: str, cat_idx: List[int]) -> Tuple[np.ndarray, np.ndarray, float, dict]:\n",
        "    try:\n",
        "        from catboost import CatBoostClassifier, Pool\n",
        "    except Exception as e:\n",
        "        print(\"[Warn] CatBoost not available, falling back to LightGBM. Error:\", e)\n",
        "        return train_lightgbm_cv(train_df, test_df, target_col)\n",
        "\n",
        "    X = train_df.drop(columns=[target_col])\n",
        "    y = train_df[target_col].values\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    oof = np.zeros(len(train_df), dtype=float)\n",
        "    test_pred = np.zeros(len(test_df), dtype=float)\n",
        "    fold_scores = []\n",
        "    feature_importance = None\n",
        "\n",
        "    params = dict(\n",
        "        loss_function=\"Logloss\",\n",
        "        eval_metric=\"AUC\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        learning_rate=0.03,\n",
        "        depth=6,\n",
        "        l2_leaf_reg=3.0,\n",
        "        iterations=10000,\n",
        "        od_type=\"Iter\",\n",
        "        od_wait=500,\n",
        "        verbose=200\n",
        "    )\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        train_pool = Pool(X_tr, label=y_tr, cat_features=cat_idx)\n",
        "        valid_pool = Pool(X_va, label=y_va, cat_features=cat_idx)\n",
        "        test_pool  = Pool(test_df, cat_features=cat_idx)\n",
        "\n",
        "        model = CatBoostClassifier(**params)\n",
        "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
        "\n",
        "        preds_va = model.predict_proba(valid_pool)[:, 1]\n",
        "        preds_te = model.predict_proba(test_pool)[:, 1]\n",
        "\n",
        "        oof[va_idx] = preds_va\n",
        "        test_pred += preds_te / FOLDS\n",
        "\n",
        "        fold_auc = roc_auc_score(y_va, preds_va)\n",
        "        fold_scores.append(fold_auc)\n",
        "        print(f\"[Fold {fold}] AUC: {fold_auc:.6f}\")\n",
        "\n",
        "        # Save FI from last fold (CatBoost: PredictionValuesChange)\n",
        "        feature_importance = dict(zip(X.columns, model.get_feature_importance(type='PredictionValuesChange')))\n",
        "\n",
        "        del model, train_pool, valid_pool, test_pool\n",
        "        gc.collect()\n",
        "\n",
        "    cv_auc = roc_auc_score(y, oof)\n",
        "    print(f\"[CV] OOF AUC: {cv_auc:.6f} | Folds: {[round(s,6) for s in fold_scores]}\")\n",
        "    return oof, test_pred, cv_auc, {\"fold_scores\": fold_scores, \"feature_importance\": feature_importance}\n",
        "\n",
        "def train_lightgbm_cv(train_df: pd.DataFrame, test_df: pd.DataFrame, target_col: str) -> Tuple[np.ndarray, np.ndarray, float, dict]:\n",
        "    import lightgbm as lgb\n",
        "\n",
        "    # Simple categorical handling: one-hot <= 32 unique, frequency encode > 32\n",
        "    y = train_df[target_col].values\n",
        "    X = train_df.drop(columns=[target_col]).copy()\n",
        "    X_te = test_df.copy()\n",
        "\n",
        "    # Determine cat vs numeric again\n",
        "    cat_cols = [c for c in X.columns if str(X[c].dtype) in (\"object\", \"category\")]\n",
        "    low_card = [c for c in cat_cols if X[c].nunique(dropna=True) <= 32]\n",
        "    high_card = [c for c in cat_cols if c not in low_card]\n",
        "\n",
        "    # One-hot low-card\n",
        "    X = pd.get_dummies(X, columns=low_card, dummy_na=True)\n",
        "    X_te = pd.get_dummies(X_te, columns=low_card, dummy_na=True)\n",
        "\n",
        "    # Align columns\n",
        "    X, X_te = X.align(X_te, join=\"left\", axis=1, fill_value=0)\n",
        "\n",
        "    # Frequency encode high-card\n",
        "    for c in high_card:\n",
        "        freq = train_df[c].value_counts(dropna=True)\n",
        "        X[c+\"_freq\"] = train_df[c].map(freq).fillna(0).values\n",
        "        X_te[c+\"_freq\"] = test_df[c].map(freq).fillna(0).values\n",
        "        # Drop raw col\n",
        "        X.drop(columns=[c], inplace=True, errors=\"ignore\")\n",
        "        X_te.drop(columns=[c], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    oof = np.zeros(len(X), dtype=float)\n",
        "    test_pred = np.zeros(len(X_te), dtype=float)\n",
        "    fold_scores = []\n",
        "\n",
        "    params = dict(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=64,\n",
        "        feature_fraction=0.8,\n",
        "        bagging_fraction=0.8,\n",
        "        bagging_freq=1,\n",
        "        min_data_in_leaf=20,\n",
        "        lambda_l1=0.0,\n",
        "        lambda_l2=0.0,\n",
        "        max_depth=-1,\n",
        "        n_estimators=10000,\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=-1\n",
        "    )\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        lgb_train = lgb.Dataset(X_tr, label=y_tr)\n",
        "        lgb_valid = lgb.Dataset(X_va, label=y_va, reference=lgb_train)\n",
        "\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            lgb_train,\n",
        "            valid_sets=[lgb_train, lgb_valid],\n",
        "            valid_names=[\"train\", \"valid\"],\n",
        "            verbose_eval=200,\n",
        "            early_stopping_rounds=500\n",
        "        )\n",
        "\n",
        "        preds_va = model.predict(X_va, num_iteration=model.best_iteration)\n",
        "        preds_te = model.predict(X_te, num_iteration=model.best_iteration)\n",
        "\n",
        "        oof[va_idx] = preds_va\n",
        "        test_pred += preds_te / FOLDS\n",
        "\n",
        "        fold_auc = roc_auc_score(y_va, preds_va)\n",
        "        fold_scores.append(fold_auc)\n",
        "        print(f\"[Fold {fold}] AUC: {fold_auc:.6f}\")\n",
        "\n",
        "        del model, lgb_train, lgb_valid\n",
        "        gc.collect()\n",
        "\n",
        "    cv_auc = roc_auc_score(y, oof)\n",
        "    print(f\"[CV] OOF AUC: {cv_auc:.6f} | Folds: {[round(s,6) for s in fold_scores]}\")\n",
        "    return oof, test_pred, cv_auc, {\"fold_scores\": fold_scores}\n",
        "\n",
        "def main():\n",
        "    train, test, sample = load_data()\n",
        "    cols = infer_columns(train)\n",
        "    id_col, target_col = cols[\"id\"], cols[\"target\"]\n",
        "    print(f\"[Info] id_col={id_col}, target_col={target_col}\")\n",
        "\n",
        "    # Basic target check\n",
        "    pos_rate = train[target_col].mean()\n",
        "    print(f\"[Info] Training rows: {len(train)} | Pos rate (y=1): {pos_rate:.4f}\")\n",
        "\n",
        "    # Prepare data for CatBoost (handles categorical cleanly)\n",
        "    train_pre, test_pre, cat_idx = prepare_catboost_data(train, test, id_col, target_col)\n",
        "\n",
        "    # Train CV\n",
        "    oof, test_pred, cv_auc, extras = train_catboost_cv(train_pre, test_pre, target_col, cat_idx)\n",
        "\n",
        "    # Simple error slicing example (optional, cheap)\n",
        "    if id_col and id_col in train.columns:\n",
        "        try:\n",
        "            df_oof = train[[id_col, target_col]].copy()\n",
        "            df_oof[\"oof\"] = oof\n",
        "            # Print AUC on top/bottom deciles by oof\n",
        "            quant = pd.qcut(df_oof[\"oof\"], 10, duplicates=\"drop\")\n",
        "            by_dec = df_oof.groupby(quant)[target_col].mean()\n",
        "            print(\"[Info] Target rate by OOF decile (lowâ†’high):\")\n",
        "            print(by_dec.to_string())\n",
        "        except Exception as e:\n",
        "            print(\"[Warn] OOF slicing skipped:\", e)\n",
        "\n",
        "    # Submission\n",
        "    sub = sample.copy()\n",
        "    # Ensure correct column names\n",
        "    if \"y\" in sub.columns:\n",
        "        sub[\"y\"] = test_pred\n",
        "    elif \"target\" in sub.columns:\n",
        "        sub[\"target\"] = test_pred\n",
        "    else:\n",
        "        # Fallback to 'y'\n",
        "        if \"y\" not in sub.columns:\n",
        "            sub.columns = [\"id\", \"y\"]\n",
        "        sub[\"y\"] = test_pred\n",
        "\n",
        "    out_name = f\"submission_{cv_auc:.5f}.csv\"\n",
        "    sub.to_csv(out_name, index=False)\n",
        "    print(f\"[Done] CV AUC: {cv_auc:.6f} | Wrote {out_name}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "id": "qiii-cAvKScL"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}